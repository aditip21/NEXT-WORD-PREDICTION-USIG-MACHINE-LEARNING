{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(\"https://archive.org/details/isbn_9783822889633\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n<!-- __ _ _ _ __| |_ (_)__ _____\\n    / _` | \\'_/ _| \\' \\\\| |\\\\ V / -_)\\n    \\\\__,_|_| \\\\__|_||_|_| \\\\_/\\\\___| -->\\n  <head data-release=ed6cd0a4>\\n    <title>Erotica universalis : NeÃÅret, Gilles : Free Download, Borrow, and Streaming : Internet Archive</title>\\n\\n          <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/>\\n    \\n        <meta name=\"google-site-verification\" content=\"Q2YSouphkkgHkFNP7FgAkc4TmBs1Gmag3uGNndb53B8\" />\\n    <meta name=\"google-site-verification\" content=\"bpjKvUvsX0lxfmjg19TLblckWkDpnptZEYsBntApxUk\" />\\n\\n    <script>\\n/* @licstart  The following is the entire license notice for the\\n * JavaScript code in this page.\\n *\\n * This program is free software: you can redistribute it and/or modify\\n * it under the terms of the GNU Affero General Public License as published by\\n * the Free Software Foundation, either version 3 of the License, or\\n * (at your option) any later version.\\n *\\n * This program is distributed in the hope that it will be useful,\\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\\n * GNU Affero General Public License for more details.\\n *\\n * You should have received a copy of the GNU Affero General Public License\\n * along with this program.  If not, see <http://www.gnu.org/licenses/>.\\n *\\n * @licend  The above is the entire license notice\\n * for the JavaScript code in this page.\\n */\\n</script>\\n              <script>window.archive'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[:1500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = response.text.split('\\n') \n",
    "data[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      }'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[253:] \n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2071"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      }        .media-menu-1 .media-menu.tx-slide.open.media-menu {         top: 100%;       }        .media-menu-1 .media-menu.tx-slide.closed.media-menu {         top: -100vh;       }        .media-menu-1 .media-menu.tx-slide.closed.media-menu {         transition-duration: 0.2s;       }        .media-menu-1 .menu-group.media-menu {         position: relative;           line-height: normal;       }        @media (min-width: 890px) {       .media-menu-1 .media-menu.media-menu {         display: inline-block;             position: static;             width: auto;             height: 5rem;       }        .media-menu-1 .media-menu.tx-slide.media-menu {         transition-property: none;       }        .media-menu-1 .media-menu.tx-slide.open.media-menu,.media-menu-1 .media-menu.tx-slide.closed.media-menu {         top: 0;       }        .media-menu-1 .menu-group.media-menu {         font-size: 0;       }        }</style><!-- Shady DOM styles for primary-nav --><style scope=\"primary-nav-1\"'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \" \".join(data) \n",
    "data[:1000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mediamenutxslideopenmediamenu', 'top', 'mediamenutxslideclosedmediamenu', 'top', 'mediamenutxslideclosedmediamenu', 'transitionduration', 'menugroupmediamenu', 'position', 'relative', 'lineheight', 'normal', 'media', 'minwidth', 'mediamenumediamenu', 'display', 'inlineblock', 'position', 'static', 'width', 'auto', 'height', 'mediamenutxslidemediamenu', 'transitionproperty', 'none', 'mediamenutxslideclosedmediamenu', 'top', 'menugroupmediamenu', 'fontsize', 'style', 'shady', 'dom', 'styles', 'for', 'primarynav', 'style', 'inputprimarynavfocus', 'outline', 'none', 'navprimarynav', 'position', 'relative', 'display', 'msgrid', 'display', 'grid', 'height', 'gridtemplateareas', 'hamburger', 'empty', 'search']\n"
     ]
    }
   ],
   "source": [
    "def clean_text(doc): \n",
    " tokens = doc.split() \n",
    " table = str.maketrans('', '', string.punctuation) \n",
    " tokens = [w.translate(table) for w in tokens] \n",
    " tokens = [word for word in tokens if word.isalpha()] \n",
    " tokens = [word.lower() for word in tokens] \n",
    " return tokens \n",
    "tokens = clean_text(data) \n",
    "print(tokens[:50]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3234"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183\n"
     ]
    }
   ],
   "source": [
    "length = 50 + 1 \n",
    "lines = [] \n",
    "for i in range(length, len(tokens)): \n",
    " seq = tokens[i-length:i] \n",
    " line = ' '.join(seq) \n",
    " lines.append(line) \n",
    " if i > 200000: \n",
    "    break \n",
    "print(len(lines)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Build LTSM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD LTSM MODEL\n",
    "import numpy as np \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts(lines) \n",
    "sequences = tokenizer.texts_to_sequences(lines) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1100,   19, 1083,   19, 1083,   92, 1081,   32,  107, 1097, 1096,\n",
       "         61,   68, 1094,    8,  108,   32,  328,   67,   36,   41, 1089,\n",
       "        194,    9, 1083,   19, 1081,   31,   37,   60,   59,   58,   33,\n",
       "         16,   37, 1079, 1078,    9,  326,   32,  107,    8,  193,    8,\n",
       "        192,   41, 1073,  323, 1072,   90])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = np.array(sequences) \n",
    "X, y = sequences[:, :-1], sequences[:,-1] \n",
    "X[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = X.shape[1] \n",
    "seq_length \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LTSM MODEL\n",
    "\n",
    "model = Sequential() \n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length)) \n",
    "model.add(LSTM(100, return_sequences=True)) \n",
    "model.add(LSTM(100)) \n",
    "model.add(Dense(100, activation='relu')) \n",
    "model.add(Dense(vocab_size, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            55100     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1102)              111302    \n",
      "=================================================================\n",
      "Total params: 317,302\n",
      "Trainable params: 317,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 5s 203ms/step - loss: 6.9918 - accuracy: 0.0258\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 6.4971 - accuracy: 0.0145\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 3s 211ms/step - loss: 6.1078 - accuracy: 0.0368\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 2s 189ms/step - loss: 6.0536 - accuracy: 0.0377\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 6.0355 - accuracy: 0.0390\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 6.0280 - accuracy: 0.0415\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 3s 211ms/step - loss: 6.0254 - accuracy: 0.0415\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 6.0237 - accuracy: 0.0415\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 3s 246ms/step - loss: 6.0236 - accuracy: 0.0415\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 3s 224ms/step - loss: 6.0197 - accuracy: 0.0415\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 6.0193 - accuracy: 0.0415\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 6.0148 - accuracy: 0.0434\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 3s 227ms/step - loss: 6.0019 - accuracy: 0.0415\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 3s 272ms/step - loss: 5.9710 - accuracy: 0.0418\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 3s 265ms/step - loss: 5.9004 - accuracy: 0.0534\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 3s 237ms/step - loss: 5.8258 - accuracy: 0.0609\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 3s 220ms/step - loss: 5.7290 - accuracy: 0.0682\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 3s 224ms/step - loss: 5.6388 - accuracy: 0.0691\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 5.5460 - accuracy: 0.0701\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 3s 247ms/step - loss: 5.4427 - accuracy: 0.0707\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 3s 232ms/step - loss: 5.3366 - accuracy: 0.0723\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 5.2129 - accuracy: 0.0804\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 5.1054 - accuracy: 0.0807\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 3s 225ms/step - loss: 4.9845 - accuracy: 0.0826\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 3s 244ms/step - loss: 4.8741 - accuracy: 0.0836\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 3s 231ms/step - loss: 5.1021 - accuracy: 0.0754\n",
      "Epoch 27/100\n",
      " 7/13 [===============>..............] - ETA: 1s - loss: 4.6736 - accuracy: 0.0898"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-f0b6d6802476>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, batch_size = 256, epochs = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'span classlabel stylescope mediabuttonwayback machinespan a mediabutton mediabutton classstylescope mediamenu xscope datamediatypetexts a classmenuitem texts stylescope mediabutton hrefhttpsarchiveorgdetailstexts dataeventclicktrackingbetatopnavnavmenutexts span classicon stylescope mediabutton svg arialabelledbytextstitleid textsdescid classstylescope mediabutton title idtextstitleid classstylescope mediabuttontexts icontitle desc idtextsdescid classstylescope mediabuttonan illustration of an open bookdesc path classfillcolor stylescope mediabutton svg span span classlabel stylescope'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "seed_text=lines[1234] \n",
    "seed_text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words): \n",
    " text = [] \n",
    " for _ in range(n_words): \n",
    "    encoded = tokenizer.texts_to_sequences([seed_text])[0] \n",
    " encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre') \n",
    " y_predict = model.predict_classes(encoded) \n",
    " predicted_word = '' \n",
    " for word, index in tokenizer.word_index.items(): \n",
    "    if index == y_predict: \n",
    "        predicted_word = word \n",
    "        break \n",
    " seed_text = seed_text + ' ' + predicted_word \n",
    " text.append(predicted_word) \n",
    " return ' '.join(text) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mediabutton'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text_seq(model, tokenizer, seq_length, seed_text, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
